{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde31416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Tuning hyperparameters for Logistic Regression ...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "âœ… Best Parameters for Logistic Regression: {'C': 0.1, 'solver': 'liblinear'}\n",
      "ğŸ† Best CV Score: 0.8450\n",
      "\n",
      "ğŸ” Tuning hyperparameters for Decision Tree ...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "âœ… Best Parameters for Decision Tree: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "ğŸ† Best CV Score: 0.7282\n",
      "\n",
      "ğŸ” Tuning hyperparameters for Random Forest ...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "âœ… Best Parameters for Random Forest: {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "ğŸ† Best CV Score: 0.8244\n",
      "\n",
      "ğŸ” Tuning hyperparameters for SVM ...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "âœ… Best Parameters for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "ğŸ† Best CV Score: 0.8324\n",
      "\n",
      "ğŸ“Š Final Model Comparison (Test Set Performance):\n",
      "Logistic Regression  - Accuracy: 0.8333\n",
      "Decision Tree        - Accuracy: 0.7333\n",
      "Random Forest        - Accuracy: 0.8333\n",
      "SVM                  - Accuracy: 0.8333\n",
      "\n",
      "ğŸš€ Best Tuned Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85        32\n",
      "           1       0.88      0.75      0.81        28\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.84      0.83      0.83        60\n",
      "weighted avg       0.84      0.83      0.83        60\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/temp_best_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸªœ Step 6: Hyperparameter Tuning\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 1ï¸âƒ£ Load preprocessed dataset\n",
    "data = pd.read_csv('../data/heart_disease_cleaned.csv')  # Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø­Ø³Ø¨ Ù…Ø´Ø±ÙˆØ¹Ùƒ\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 2ï¸âƒ£ Define models & hyperparameter grids\n",
    "models = {\n",
    "    \"Logistic Regression\": (\n",
    "        LogisticRegression(max_iter=500),\n",
    "        {\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'lbfgs']\n",
    "        }\n",
    "    ),\n",
    "    \"Decision Tree\": (\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        {\n",
    "            'max_depth': [None, 3, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"SVM\": (\n",
    "        SVC(),\n",
    "        {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf', 'poly'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "# 3ï¸âƒ£ Run GridSearchCV for each model\n",
    "best_models = {}\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\nğŸ” Tuning hyperparameters for {name} ...\")\n",
    "    grid = GridSearchCV(model, params, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"âœ… Best Parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"ğŸ† Best CV Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "# 4ï¸âƒ£ Evaluate all tuned models on test set\n",
    "print(\"\\nğŸ“Š Final Model Comparison (Test Set Performance):\")\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name:20s} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 5ï¸âƒ£ Select the best performing model\n",
    "best_model_name = max(best_models, key=lambda m: accuracy_score(y_test, best_models[m].predict(X_test)))\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nğŸš€ Best Tuned Model: {best_model_name}\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "import joblib\n",
    "joblib.dump(best_model, '../models/temp_best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fb6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
